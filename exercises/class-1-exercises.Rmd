---
title: "Exercises for class 1"
output: html_document
date: "13-02-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
```

# Exercises for Class 1

## Supporting code

Below is code from Chapter 2 of the book that you can use to do the exercises. Not all the code you require is here though. Make sure to not rush it and take time to play around with each function. :))

```{r}
# Grid Approximation

# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = rep(1, 20)

# compute likelihood at each value in grid
likelihood = dbinom(5, size = 7, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

```

## Exercises

### Easy

2E1. 

```{r}
# Your answer here.

"The Correct answers are (2) and (4)"
```

2E2.

```{r}

# Your answer here.
"The Correct answer is (3)"

```

2E3.

```{r}

# Your answer here.
"The Correct answers are (1) and (4)"

```

2E4.

```{r}

# Discuss in pairs/groups. Ask me for a hint if you feel like it.
"Probability does not have an objective reality as it used to look into the future (describing uncertainty), given the knowledge at the current moment. Objective reality is based on unlimited knowledge/capped knowledge in the field specified."

```

### Medium

2M1.

```{r}

# Write your code here.
"(a)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = rep(1, 20)

# compute likelihood at each value in grid
likelihood = dbinom(3, size = 3, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

"(b)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = rep(1, 20)

# compute likelihood at each value in grid
likelihood = dbinom(3, size = 4, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

"(c)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = rep(1, 20)

# compute likelihood at each value in grid
likelihood = dbinom(5, size = 7, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

```

2M2.

```{r}
# In the book, McElreath says that we can do much better than choosing a uniform prior for estimating the coverage of water. Is this what we are doing here? How does that impact our estimation?
pacman::p_load("extraDistr")
"(a)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
prior

# compute likelihood at each value in grid
likelihood = dbinom(3, size = 3, prob = p_grid)


# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)


# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

"(b)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)

# compute likelihood at each value in grid
likelihood = dbinom(3, size = 4, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

"(c)"
# define grid
p_grid = seq(from = 0, to = 1, length.out=20)


# define prior
prior = c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)

# compute likelihood at each value in grid
likelihood = dbinom(5, size = 7, prob = p_grid)
likelihood

# compute product of likelihood and prior
unstd.posterior = likelihood * prior


# standardize the posterior so it sums to 1
posterior = unstd.posterior / sum(unstd.posterior)
posterior

# plot the distribution
plot(p_grid, posterior, type = "b",
     xlab = "probability of water", ylab = "posterior_probability")
mtext("20 points")

```

2M3.

```{r}

# Use the Bayes formula!

(0.3*0.5)/0.65


```

For the exercises below, I highly suggest you to grab a piece of paper and try to solve the problems in a 'visual' way.

2M4.

```{r}

# Write your probability here.
2/3

```

2M5.

```{r}

# Write your probability here.
4/5

```

2M6.

```{r}

# Write your probability here.
2/4

```
